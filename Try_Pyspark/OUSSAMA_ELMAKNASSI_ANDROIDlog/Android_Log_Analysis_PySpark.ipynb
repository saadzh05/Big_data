{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# Analyse des Logs Android avec PySpark\n",
                "## Par OUSSAMA ELMAKNASSI\n",
                "\n",
                "Ce notebook analyse les logs Android en utilisant PySpark pour compter :\n",
                "- Les messages par **niveau** (I, D, E, W, V)\n",
                "- Les messages par **heure**\n",
                "- Les messages par **minute**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## 1. Installation et Configuration de PySpark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install-pyspark"
            },
            "outputs": [],
            "source": [
                "# Installation de PySpark\n",
                "!pip install pyspark\n",
                "\n",
                "# Installation de Java (d√©j√† disponible sur Colab)\n",
                "import os\n",
                "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
                "os.environ[\"SPARK_HOME\"] = \"/content/spark\"\n",
                "\n",
                "print(\"‚úì PySpark install√© et configur√©\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload"
            },
            "source": [
                "## 2. Upload du fichier Android.log\n",
                "\n",
                "**Instructions :**\n",
                "1. Ex√©cutez la cellule ci-dessous\n",
                "2. Cliquez sur \"Choose Files\"\n",
                "3. S√©lectionnez votre fichier `Android.log`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload-file"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import io\n",
                "\n",
                "print(\"üìÅ Veuillez uploader votre fichier Android.log...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Sauvegarder le fichier\n",
                "for filename in uploaded.keys():\n",
                "    print(f\"‚úì Fichier upload√©: {filename} ({len(uploaded[filename])} bytes)\")\n",
                "    with open('Android.log', 'wb') as f:\n",
                "        f.write(uploaded[filename])\n",
                "\n",
                "print(\"\\n‚úì Fichier pr√™t pour l'analyse !\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "init-spark"
            },
            "source": [
                "## 3. Initialisation de Spark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "spark-context"
            },
            "outputs": [],
            "source": [
                "from pyspark import SparkContext, SparkConf\n",
                "import re\n",
                "\n",
                "# Configuration de Spark\n",
                "conf = SparkConf().setAppName(\"Android Log Analysis\").setMaster(\"local[*]\")\n",
                "\n",
                "# Arr√™ter le contexte existant s'il y en a un\n",
                "try:\n",
                "    sc.stop()\n",
                "except:\n",
                "    pass\n",
                "\n",
                "# Cr√©er un nouveau contexte Spark\n",
                "sc = SparkContext(conf=conf)\n",
                "\n",
                "print(\"‚úì SparkContext initialis√©\")\n",
                "print(f\"  - Version Spark: {sc.version}\")\n",
                "print(f\"  - Master: {sc.master}\")\n",
                "print(f\"  - Application: {sc.appName}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "load-data"
            },
            "source": [
                "## 4. Chargement des donn√©es"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load-rdd"
            },
            "outputs": [],
            "source": [
                "# Charger le fichier de logs dans un RDD\n",
                "log_RDD = sc.textFile(\"Android.log\")\n",
                "\n",
                "# Compter le nombre total de lignes\n",
                "total_lines = log_RDD.count()\n",
                "print(f\"‚úì Fichier charg√©: {total_lines:,} lignes\")\n",
                "\n",
                "# Afficher quelques exemples\n",
                "print(\"\\nüìã Exemples de lignes:\")\n",
                "for i, line in enumerate(log_RDD.take(5), 1):\n",
                "    print(f\"  {i}. {line[:100]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "parse"
            },
            "source": [
                "## 5. Parsing des logs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "parse-functions"
            },
            "outputs": [],
            "source": [
                "def parse_log_line(line):\n",
                "    \"\"\"Extrait le timestamp et le level d'une ligne de log\"\"\"\n",
                "    try:\n",
                "        # Chercher le timestamp\n",
                "        timestamp_match = re.search(r'(\\d{4}-\\d{2}-\\d{2}[T ]\\d{2}:\\d{2})|' +\n",
                "                                   r'(\\d{2}-\\d{2} \\d{2}:\\d{2})|' +\n",
                "                                   r'(\\d{2}:\\d{2}:\\d{2})', line)\n",
                "        \n",
                "        # Chercher le level (E, W, I, D, V)\n",
                "        level_match = re.search(r'\\b([EWIDV])\\b|\\[(ERROR|WARN|WARNING|INFO|DEBUG|VERBOSE)\\]', \n",
                "                               line, re.IGNORECASE)\n",
                "        \n",
                "        timestamp = timestamp_match.group(0) if timestamp_match else None\n",
                "        level = level_match.group(1) or level_match.group(2) if level_match else 'UNKNOWN'\n",
                "        \n",
                "        return (timestamp, level.upper())\n",
                "    except:\n",
                "        return (None, 'UNKNOWN')\n",
                "\n",
                "def extract_hour(timestamp):\n",
                "    \"\"\"Extrait l'heure d'un timestamp\"\"\"\n",
                "    if not timestamp:\n",
                "        return 'UNKNOWN'\n",
                "    try:\n",
                "        hour_match = re.search(r'(\\d{2}):\\d{2}', timestamp)\n",
                "        return hour_match.group(1) + ':00' if hour_match else 'UNKNOWN'\n",
                "    except:\n",
                "        return 'UNKNOWN'\n",
                "\n",
                "def extract_minute(timestamp):\n",
                "    \"\"\"Extrait l'heure et la minute d'un timestamp\"\"\"\n",
                "    if not timestamp:\n",
                "        return 'UNKNOWN'\n",
                "    try:\n",
                "        minute_match = re.search(r'(\\d{2}:\\d{2})', timestamp)\n",
                "        return minute_match.group(1) if minute_match else 'UNKNOWN'\n",
                "    except:\n",
                "        return 'UNKNOWN'\n",
                "\n",
                "# Parser toutes les lignes\n",
                "parsed_RDD = log_RDD.map(parse_log_line)\n",
                "print(\"‚úì Fonctions de parsing d√©finies\")\n",
                "print(\"‚úì RDD pars√© cr√©√©\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "count-level"
            },
            "source": [
                "## 6. COUNT PAR NIVEAU (LEVEL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "analyze-level"
            },
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"COUNT PAR NIVEAU (LEVEL)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Compter par niveau\n",
                "level_counts = parsed_RDD.map(lambda x: (x[1], 1)) \\\n",
                "                        .reduceByKey(lambda a, b: a + b) \\\n",
                "                        .sortBy(lambda x: x[1], ascending=False)\n",
                "\n",
                "level_results = level_counts.collect()\n",
                "\n",
                "# Afficher les r√©sultats\n",
                "for level, count in level_results:\n",
                "    print(f\"{level}: {count:,} messages\")\n",
                "\n",
                "print(f\"\\nTotal: {sum([count for _, count in level_results]):,} messages\")\n",
                "\n",
                "# Sauvegarder\n",
                "level_counts.map(lambda x: f\"{x[0]}: {x[1]}\").saveAsTextFile(\"count_by_level\")\n",
                "print(\"\\n‚úì Sauvegard√© dans: count_by_level/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "count-hour"
            },
            "source": [
                "## 7. COUNT PAR HEURE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "analyze-hour"
            },
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COUNT PAR HEURE\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Compter par heure\n",
                "hour_counts = parsed_RDD.map(lambda x: (extract_hour(x[0]), 1)) \\\n",
                "                       .reduceByKey(lambda a, b: a + b) \\\n",
                "                       .sortBy(lambda x: x[0])\n",
                "\n",
                "hour_results = hour_counts.collect()\n",
                "\n",
                "# Afficher les r√©sultats\n",
                "for hour, count in hour_results:\n",
                "    print(f\"{hour}: {count:,} messages\")\n",
                "\n",
                "print(f\"\\nTotal: {sum([count for _, count in hour_results]):,} messages\")\n",
                "\n",
                "# Sauvegarder\n",
                "hour_counts.map(lambda x: f\"{x[0]}: {x[1]}\").saveAsTextFile(\"count_by_hour\")\n",
                "print(\"\\n‚úì Sauvegard√© dans: count_by_hour/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "count-minute"
            },
            "source": [
                "## 8. COUNT PAR MINUTE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "analyze-minute"
            },
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COUNT PAR MINUTE (Top 50)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Compter par minute\n",
                "minute_counts = parsed_RDD.map(lambda x: (extract_minute(x[0]), 1)) \\\n",
                "                         .reduceByKey(lambda a, b: a + b) \\\n",
                "                         .sortBy(lambda x: x[1], ascending=False)\n",
                "\n",
                "# Afficher le top 50\n",
                "minute_results = minute_counts.take(50)\n",
                "for minute, count in minute_results:\n",
                "    print(f\"{minute}: {count:,} messages\")\n",
                "\n",
                "total_minutes = minute_counts.count()\n",
                "print(f\"\\nNombre total de minutes diff√©rentes: {total_minutes:,}\")\n",
                "\n",
                "# Sauvegarder\n",
                "minute_counts.map(lambda x: f\"{x[0]}: {x[1]}\").saveAsTextFile(\"count_by_minute\")\n",
                "print(\"\\n‚úì Sauvegard√© dans: count_by_minute/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "stats"
            },
            "source": [
                "## 9. Statistiques globales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "global-stats"
            },
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"STATISTIQUES GLOBALES\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "total_logs = log_RDD.count()\n",
                "print(f\"Nombre total de lignes de log: {total_logs:,}\")\n",
                "\n",
                "# Statistiques sur les minutes\n",
                "minute_stats = minute_counts.map(lambda x: x[1]).stats()\n",
                "print(f\"\\nMessages par minute:\")\n",
                "print(f\"  - Moyenne: {minute_stats.mean():,.2f}\")\n",
                "print(f\"  - Maximum: {minute_stats.max():,}\")\n",
                "print(f\"  - Minimum: {minute_stats.min():,}\")\n",
                "\n",
                "# Statistiques sur les heures\n",
                "hour_stats = hour_counts.map(lambda x: x[1]).stats()\n",
                "print(f\"\\nMessages par heure:\")\n",
                "print(f\"  - Moyenne: {hour_stats.mean():,.2f}\")\n",
                "print(f\"  - Maximum: {hour_stats.max():,}\")\n",
                "print(f\"  - Minimum: {hour_stats.min():,}\")\n",
                "\n",
                "# R√©partition par niveau\n",
                "print(f\"\\nR√©partition par niveau:\")\n",
                "total = sum([count for _, count in level_results])\n",
                "for level, count in level_results:\n",
                "    percentage = (count / total) * 100\n",
                "    print(f\"  - {level}: {percentage:.2f}%\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ANALYSE TERMIN√âE !\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download"
            },
            "source": [
                "## 10. T√©l√©charger les r√©sultats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download-results"
            },
            "outputs": [],
            "source": [
                "# Cr√©er un fichier ZIP avec tous les r√©sultats\n",
                "!zip -r results.zip count_by_level count_by_hour count_by_minute\n",
                "\n",
                "# T√©l√©charger le fichier ZIP\n",
                "from google.colab import files\n",
                "files.download('results.zip')\n",
                "\n",
                "print(\"‚úì R√©sultats t√©l√©charg√©s !\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "cleanup"
            },
            "source": [
                "## 11. Nettoyage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "stop-spark"
            },
            "outputs": [],
            "source": [
                "# Arr√™ter le contexte Spark\n",
                "sc.stop()\n",
                "print(\"‚úì SparkContext arr√™t√©\")"
            ]
        }
    ]
}